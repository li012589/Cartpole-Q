# A Q-learning version of CartPole

A naive Q-learning implement of Q-learning with memory replay and soft target network.

Here's some gif to show the process:

![alt text](https://github.com/li012589/Cartpole-Q/blob/master/demo/Qlearning.gif "Train process")
![alt text](https://github.com/li012589/Cartpole-Q/blob/master/demo/combine_theta0-compressed.gif "View the output of the Q network")

## HOW TO RUN

'''
python ./main.py
'''
It will take few hours to balance the pole.
## DEMO
Do
1. Move the files in demo to the savedQnetwork folders 
2. Change "RENDER_ENV" to "True" in main.py
to run the demo

## TO BE MORE SPECIFIC

